docker build --pull --target devel --file docker/Dockerfile.multi --tag tensorrt_llm/devel:latest .
git submodule update --init --recursive
docker run --rm -it --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 --gpus=all --volume ${PWD}:/code/tensorrt_llm --workdir /code/tensorrt_llm tensorrt_llm/devel:latest
# in container
git config --global --add safe.directory /code/tensorrt_llm/cpp/build/_deps/googletest-src
rm -rf build
python3 ./scripts/build_wheel.py --trt_root /usr/local/tensorrt --clean -f
pip install -e ./
   or pip install -e build/<TRT-LLM wheel name> 
pip install parameterized
pytest tests/unittest/llmapi/test_executor.py
    or pytest tests/unittest/llmapi/test_executor.py::test_ZeroMqQueue_sync_async -v
    pytest tests/unittest/llmapi/test_executor.py::test_ZeroMqQueue_serialization_complicated_dataclass -v
trtllm-serve TinyLlama/TinyLlama-1.1B-Chat-v1.0 --num_postprocess_workers 3

# new terminal
docker exec -it CONTAINER bash
curl http://localhost:8000/v1/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "prompt": "Where is New York?",
        "max_tokens": 16,
        "temperature": 0
    }'

# To build the TensorRT-LLM code.

#testing from in container
pip install parameterized
pytest tests/unittest/llmapi/test_executor.py::test_ZeroMqQueue_sync_async -v

pip install -r requirements-dev.txt
cd tests/
pytest ./ #other tests in the tests folder


# Deploy TensorRT-LLM in your environment.
pip install ./build/tensorrt_llm*.whl
# start the server
trtllm-serve TinyLlama/TinyLlama-1.1B-Chat-v1.0
# run server commands
curl http://localhost:8000/v1/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
        "prompt": "Where is New York?",
        "max_tokens": 16,
        "temperature": 0
    }'

curl -X GET http://localhost:8000/metrics

run test cases






Yibin Li
:spiral_calendar_pad:  6:13 PM
I didn't find any good example of complicated dataclass in testing, so I wrote a unit test similar to the test_ZeroMqQueue_sync_async that checks for KvCacheRetentionConfig and embedding_bias serialization / deserialization
test_executor.diff
 
diff --git a/tests/unittest/llmapi/test_executor.py b/tests/unittest/llmapi/test_executor.py
index 82a33e44..b7150c6f 100644
--- a/tests/unittest/llmapi/test_executor.py
+++ b/tests/unittest/llmapi/test_executor.py
@@ -1,4 +1,5 @@
Click to expand inline (63 lines)


6:14
We should probably write a similar unit test for Result dataclass because it also contains various torch.tensor. Let me know if I can help with this
6:18
Also with the trtllm-serve command I shared above, if you add an extra flag --num_postprocess_workers for worker > 1, IPC will use put_async and get_async, and invoke the async message dataclass, PostprocWorker.Input and PostprocWorker.Output . You may also want to test that (edited) 




NEW

